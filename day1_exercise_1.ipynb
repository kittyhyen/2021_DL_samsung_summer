{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18.)\n",
      "l을 w로 미분한 값은 18.0\n"
     ]
    }
   ],
   "source": [
    "a = w*3\n",
    "\n",
    "l = a**2\n",
    "\n",
    "l.backward()\n",
    "\n",
    "print(w.grad)\n",
    "print('l을 w로 미분한 값은 {}'.format(w.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0/3000 w:0.020 b:0.020 cost: 1.667\n",
      "Epoch   100/3000 w:0.782 b:0.509 cost: 0.283\n",
      "Epoch   200/3000 w:0.981 b:0.403 cost: 0.230\n",
      "Epoch   300/3000 w:1.114 b:0.301 cost: 0.202\n",
      "Epoch   400/3000 w:1.212 b:0.225 cost: 0.186\n",
      "Epoch   500/3000 w:1.285 b:0.168 cost: 0.178\n",
      "Epoch   600/3000 w:1.340 b:0.125 cost: 0.173\n",
      "Epoch   700/3000 w:1.380 b:0.093 cost: 0.170\n",
      "Epoch   800/3000 w:1.411 b:0.070 cost: 0.169\n",
      "Epoch   900/3000 w:1.433 b:0.052 cost: 0.168\n",
      "Epoch  1000/3000 w:1.450 b:0.039 cost: 0.167\n",
      "Epoch  1100/3000 w:1.463 b:0.029 cost: 0.167\n",
      "Epoch  1200/3000 w:1.472 b:0.022 cost: 0.167\n",
      "Epoch  1300/3000 w:1.479 b:0.016 cost: 0.167\n",
      "Epoch  1400/3000 w:1.485 b:0.012 cost: 0.167\n",
      "Epoch  1500/3000 w:1.488 b:0.009 cost: 0.167\n",
      "Epoch  1600/3000 w:1.491 b:0.007 cost: 0.167\n",
      "Epoch  1700/3000 w:1.494 b:0.005 cost: 0.167\n",
      "Epoch  1800/3000 w:1.495 b:0.004 cost: 0.167\n",
      "Epoch  1900/3000 w:1.496 b:0.003 cost: 0.167\n",
      "Epoch  2000/3000 w:1.497 b:0.002 cost: 0.167\n",
      "Epoch  2100/3000 w:1.498 b:0.002 cost: 0.167\n",
      "Epoch  2200/3000 w:1.499 b:0.001 cost: 0.167\n",
      "Epoch  2300/3000 w:1.499 b:0.001 cost: 0.167\n",
      "Epoch  2400/3000 w:1.499 b:0.001 cost: 0.167\n",
      "Epoch  2500/3000 w:1.499 b:0.000 cost: 0.167\n",
      "Epoch  2600/3000 w:1.500 b:0.000 cost: 0.167\n",
      "Epoch  2700/3000 w:1.500 b:0.000 cost: 0.167\n",
      "Epoch  2800/3000 w:1.500 b:0.000 cost: 0.167\n",
      "Epoch  2900/3000 w:1.500 b:0.000 cost: 0.167\n",
      "Epoch  3000/3000 w:1.500 b:0.000 cost: 0.167\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "\n",
    "x_train = torch.FloatTensor([[0], [1], [1]])\n",
    "y_train = torch.FloatTensor([[0], [1], [2]])\n",
    "\n",
    "w = torch.zeros(1, requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "optimizer = optim.SGD([w, b] , lr = 0.01)\n",
    "\n",
    "nb_epochs = 3000\n",
    "\n",
    "for epoch in range( nb_epochs + 1):\n",
    "    \n",
    "    hypothesis = x_train * w + b \n",
    "\n",
    "    cost = torch.mean( (hypothesis - y_train)**2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0 :\n",
    "        print( 'Epoch {:5d}/{} w:{:.3f} b:{:.3f} cost: {:.3f}' \n",
    "              .format(epoch, nb_epochs, w.item(), b.item(), cost.item() ))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0/1000 cost: 29661.801\n",
      "tensor([0.2940, 0.2936, 0.2974], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   100/1000 cost: 1.564\n",
      "tensor([0.6735, 0.6610, 0.6762], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   200/1000 cost: 1.498\n",
      "tensor([0.6789, 0.6550, 0.6768], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   300/1000 cost: 1.435\n",
      "tensor([0.6843, 0.6491, 0.6773], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   400/1000 cost: 1.376\n",
      "tensor([0.6894, 0.6434, 0.6778], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   500/1000 cost: 1.319\n",
      "tensor([0.6945, 0.6379, 0.6783], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   600/1000 cost: 1.266\n",
      "tensor([0.6994, 0.6326, 0.6787], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   700/1000 cost: 1.216\n",
      "tensor([0.7042, 0.6273, 0.6791], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   800/1000 cost: 1.168\n",
      "tensor([0.7089, 0.6223, 0.6795], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   900/1000 cost: 1.122\n",
      "tensor([0.7135, 0.6173, 0.6798], grad_fn=<SqueezeBackward0>)\n",
      "Epoch  1000/1000 cost: 1.079\n",
      "tensor([0.7179, 0.6125, 0.6801], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "\n",
    "x_train = torch.FloatTensor([[73,80,75], [93,88,93], [89, 91, 90],[96,98,100],[73,66,70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "w = torch.zeros((3, 1), requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "optimizer = optim.SGD([w, b] , lr = 1e-5)\n",
    "\n",
    "nb_epochs = 1000\n",
    "\n",
    "for epoch in range( nb_epochs + 1):\n",
    "    \n",
    "    #hypothesis = x_train * w + b \n",
    "    hypothesis = x_train.matmul(w) + b \n",
    "    \n",
    "    #cost = torch.mean( (hypothesis - y_train)**2)\n",
    "    cost = F.mse_loss(hypothesis, y_train)\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0 :\n",
    "        print( 'Epoch {:5d}/{} cost: {:.3f}' \n",
    "              .format(epoch, nb_epochs, cost.item() ))\n",
    "        print( w.squeeze() ) \n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0/1000 cost: 29661.801\n",
      "tensor([0.2940, 0.2936, 0.2974], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   100/1000 cost: 1.564\n",
      "tensor([0.6735, 0.6610, 0.6762], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   200/1000 cost: 1.498\n",
      "tensor([0.6789, 0.6550, 0.6768], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   300/1000 cost: 1.435\n",
      "tensor([0.6843, 0.6491, 0.6773], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   400/1000 cost: 1.376\n",
      "tensor([0.6894, 0.6434, 0.6778], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   500/1000 cost: 1.319\n",
      "tensor([0.6945, 0.6379, 0.6783], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   600/1000 cost: 1.266\n",
      "tensor([0.6994, 0.6326, 0.6787], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   700/1000 cost: 1.216\n",
      "tensor([0.7042, 0.6273, 0.6791], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   800/1000 cost: 1.168\n",
      "tensor([0.7089, 0.6223, 0.6795], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   900/1000 cost: 1.122\n",
      "tensor([0.7135, 0.6173, 0.6798], grad_fn=<SqueezeBackward0>)\n",
      "Epoch  1000/1000 cost: 1.079\n",
      "tensor([0.7179, 0.6125, 0.6801], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "\n",
    "x_train = torch.FloatTensor([[73,80,75], [93,88,93], [89, 91, 90],[96,98,100],[73,66,70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "w = torch.zeros((3, 1), requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "optimizer = optim.SGD([w, b] , lr = 1e-5)\n",
    "loss = nn.MSELoss() \n",
    "\n",
    "nb_epochs = 1000\n",
    "\n",
    "for epoch in range( nb_epochs + 1):\n",
    "    \n",
    "    #hypothesis = x_train * w + b \n",
    "    hypothesis = x_train.matmul(w) + b \n",
    "    \n",
    "    #cost = torch.mean( (hypothesis - y_train)**2)\n",
    "    #cost = F.mse_loss(hypothesis, y_train)\n",
    "    cost = loss(hypothesis, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0 :\n",
    "        print( 'Epoch {:5d}/{} cost: {:.3f}' \n",
    "              .format(epoch, nb_epochs, cost.item() ))\n",
    "        print( w.squeeze() ) \n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> linear model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear( 3,1 )   #-> 맞는 숫자 채우기 \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/500 Cost: 22692.912109\n",
      "Epoch    1/500 Cost: 7113.770996\n",
      "Epoch    2/500 Cost: 2230.537842\n",
      "Epoch    3/500 Cost: 699.903442\n",
      "Epoch    4/500 Cost: 220.130249\n",
      "Epoch    5/500 Cost: 69.746819\n",
      "Epoch    6/500 Cost: 22.609676\n",
      "Epoch    7/500 Cost: 7.834702\n",
      "Epoch    8/500 Cost: 3.203477\n",
      "Epoch    9/500 Cost: 1.751783\n",
      "Epoch   10/500 Cost: 1.296692\n",
      "Epoch   11/500 Cost: 1.154033\n",
      "Epoch   12/500 Cost: 1.109261\n",
      "Epoch   13/500 Cost: 1.095205\n",
      "Epoch   14/500 Cost: 1.090752\n",
      "Epoch   15/500 Cost: 1.089318\n",
      "Epoch   16/500 Cost: 1.088817\n",
      "Epoch   17/500 Cost: 1.088630\n",
      "Epoch   18/500 Cost: 1.088531\n",
      "Epoch   19/500 Cost: 1.088463\n",
      "Epoch   20/500 Cost: 1.088397\n",
      "Epoch   21/500 Cost: 1.088350\n",
      "Epoch   22/500 Cost: 1.088286\n",
      "Epoch   23/500 Cost: 1.088232\n",
      "Epoch   24/500 Cost: 1.088177\n",
      "Epoch   25/500 Cost: 1.088111\n",
      "Epoch   26/500 Cost: 1.088044\n",
      "Epoch   27/500 Cost: 1.087991\n",
      "Epoch   28/500 Cost: 1.087932\n",
      "Epoch   29/500 Cost: 1.087891\n",
      "Epoch   30/500 Cost: 1.087817\n",
      "Epoch   31/500 Cost: 1.087770\n",
      "Epoch   32/500 Cost: 1.087718\n",
      "Epoch   33/500 Cost: 1.087650\n",
      "Epoch   34/500 Cost: 1.087600\n",
      "Epoch   35/500 Cost: 1.087547\n",
      "Epoch   36/500 Cost: 1.087480\n",
      "Epoch   37/500 Cost: 1.087419\n",
      "Epoch   38/500 Cost: 1.087359\n",
      "Epoch   39/500 Cost: 1.087313\n",
      "Epoch   40/500 Cost: 1.087250\n",
      "Epoch   41/500 Cost: 1.087181\n",
      "Epoch   42/500 Cost: 1.087139\n",
      "Epoch   43/500 Cost: 1.087083\n",
      "Epoch   44/500 Cost: 1.087015\n",
      "Epoch   45/500 Cost: 1.086972\n",
      "Epoch   46/500 Cost: 1.086908\n",
      "Epoch   47/500 Cost: 1.086845\n",
      "Epoch   48/500 Cost: 1.086794\n",
      "Epoch   49/500 Cost: 1.086737\n",
      "Epoch   50/500 Cost: 1.086679\n",
      "Epoch   51/500 Cost: 1.086611\n",
      "Epoch   52/500 Cost: 1.086578\n",
      "Epoch   53/500 Cost: 1.086501\n",
      "Epoch   54/500 Cost: 1.086442\n",
      "Epoch   55/500 Cost: 1.086381\n",
      "Epoch   56/500 Cost: 1.086349\n",
      "Epoch   57/500 Cost: 1.086275\n",
      "Epoch   58/500 Cost: 1.086209\n",
      "Epoch   59/500 Cost: 1.086176\n",
      "Epoch   60/500 Cost: 1.086097\n",
      "Epoch   61/500 Cost: 1.086045\n",
      "Epoch   62/500 Cost: 1.085988\n",
      "Epoch   63/500 Cost: 1.085945\n",
      "Epoch   64/500 Cost: 1.085878\n",
      "Epoch   65/500 Cost: 1.085825\n",
      "Epoch   66/500 Cost: 1.085757\n",
      "Epoch   67/500 Cost: 1.085715\n",
      "Epoch   68/500 Cost: 1.085649\n",
      "Epoch   69/500 Cost: 1.085595\n",
      "Epoch   70/500 Cost: 1.085529\n",
      "Epoch   71/500 Cost: 1.085489\n",
      "Epoch   72/500 Cost: 1.085423\n",
      "Epoch   73/500 Cost: 1.085363\n",
      "Epoch   74/500 Cost: 1.085312\n",
      "Epoch   75/500 Cost: 1.085246\n",
      "Epoch   76/500 Cost: 1.085186\n",
      "Epoch   77/500 Cost: 1.085146\n",
      "Epoch   78/500 Cost: 1.085086\n",
      "Epoch   79/500 Cost: 1.085019\n",
      "Epoch   80/500 Cost: 1.084972\n",
      "Epoch   81/500 Cost: 1.084910\n",
      "Epoch   82/500 Cost: 1.084851\n",
      "Epoch   83/500 Cost: 1.084800\n",
      "Epoch   84/500 Cost: 1.084744\n",
      "Epoch   85/500 Cost: 1.084684\n",
      "Epoch   86/500 Cost: 1.084626\n",
      "Epoch   87/500 Cost: 1.084568\n",
      "Epoch   88/500 Cost: 1.084520\n",
      "Epoch   89/500 Cost: 1.084447\n",
      "Epoch   90/500 Cost: 1.084404\n",
      "Epoch   91/500 Cost: 1.084354\n",
      "Epoch   92/500 Cost: 1.084285\n",
      "Epoch   93/500 Cost: 1.084212\n",
      "Epoch   94/500 Cost: 1.084169\n",
      "Epoch   95/500 Cost: 1.084120\n",
      "Epoch   96/500 Cost: 1.084059\n",
      "Epoch   97/500 Cost: 1.084010\n",
      "Epoch   98/500 Cost: 1.083946\n",
      "Epoch   99/500 Cost: 1.083890\n",
      "Epoch  100/500 Cost: 1.083824\n",
      "Epoch  101/500 Cost: 1.083777\n",
      "Epoch  102/500 Cost: 1.083724\n",
      "Epoch  103/500 Cost: 1.083651\n",
      "Epoch  104/500 Cost: 1.083612\n",
      "Epoch  105/500 Cost: 1.083550\n",
      "Epoch  106/500 Cost: 1.083488\n",
      "Epoch  107/500 Cost: 1.083425\n",
      "Epoch  108/500 Cost: 1.083380\n",
      "Epoch  109/500 Cost: 1.083323\n",
      "Epoch  110/500 Cost: 1.083266\n",
      "Epoch  111/500 Cost: 1.083210\n",
      "Epoch  112/500 Cost: 1.083146\n",
      "Epoch  113/500 Cost: 1.083086\n",
      "Epoch  114/500 Cost: 1.083038\n",
      "Epoch  115/500 Cost: 1.082971\n",
      "Epoch  116/500 Cost: 1.082935\n",
      "Epoch  117/500 Cost: 1.082872\n",
      "Epoch  118/500 Cost: 1.082811\n",
      "Epoch  119/500 Cost: 1.082753\n",
      "Epoch  120/500 Cost: 1.082700\n",
      "Epoch  121/500 Cost: 1.082637\n",
      "Epoch  122/500 Cost: 1.082581\n",
      "Epoch  123/500 Cost: 1.082529\n",
      "Epoch  124/500 Cost: 1.082471\n",
      "Epoch  125/500 Cost: 1.082418\n",
      "Epoch  126/500 Cost: 1.082360\n",
      "Epoch  127/500 Cost: 1.082303\n",
      "Epoch  128/500 Cost: 1.082238\n",
      "Epoch  129/500 Cost: 1.082194\n",
      "Epoch  130/500 Cost: 1.082138\n",
      "Epoch  131/500 Cost: 1.082075\n",
      "Epoch  132/500 Cost: 1.082017\n",
      "Epoch  133/500 Cost: 1.081959\n",
      "Epoch  134/500 Cost: 1.081900\n",
      "Epoch  135/500 Cost: 1.081860\n",
      "Epoch  136/500 Cost: 1.081786\n",
      "Epoch  137/500 Cost: 1.081737\n",
      "Epoch  138/500 Cost: 1.081677\n",
      "Epoch  139/500 Cost: 1.081618\n",
      "Epoch  140/500 Cost: 1.081566\n",
      "Epoch  141/500 Cost: 1.081517\n",
      "Epoch  142/500 Cost: 1.081460\n",
      "Epoch  143/500 Cost: 1.081407\n",
      "Epoch  144/500 Cost: 1.081348\n",
      "Epoch  145/500 Cost: 1.081292\n",
      "Epoch  146/500 Cost: 1.081231\n",
      "Epoch  147/500 Cost: 1.081173\n",
      "Epoch  148/500 Cost: 1.081117\n",
      "Epoch  149/500 Cost: 1.081074\n",
      "Epoch  150/500 Cost: 1.081004\n",
      "Epoch  151/500 Cost: 1.080948\n",
      "Epoch  152/500 Cost: 1.080899\n",
      "Epoch  153/500 Cost: 1.080839\n",
      "Epoch  154/500 Cost: 1.080773\n",
      "Epoch  155/500 Cost: 1.080734\n",
      "Epoch  156/500 Cost: 1.080674\n",
      "Epoch  157/500 Cost: 1.080604\n",
      "Epoch  158/500 Cost: 1.080565\n",
      "Epoch  159/500 Cost: 1.080500\n",
      "Epoch  160/500 Cost: 1.080432\n",
      "Epoch  161/500 Cost: 1.080384\n",
      "Epoch  162/500 Cost: 1.080334\n",
      "Epoch  163/500 Cost: 1.080272\n",
      "Epoch  164/500 Cost: 1.080209\n",
      "Epoch  165/500 Cost: 1.080174\n",
      "Epoch  166/500 Cost: 1.080108\n",
      "Epoch  167/500 Cost: 1.080043\n",
      "Epoch  168/500 Cost: 1.080009\n",
      "Epoch  169/500 Cost: 1.079944\n",
      "Epoch  170/500 Cost: 1.079874\n",
      "Epoch  171/500 Cost: 1.079830\n",
      "Epoch  172/500 Cost: 1.079764\n",
      "Epoch  173/500 Cost: 1.079716\n",
      "Epoch  174/500 Cost: 1.079665\n",
      "Epoch  175/500 Cost: 1.079601\n",
      "Epoch  176/500 Cost: 1.079541\n",
      "Epoch  177/500 Cost: 1.079497\n",
      "Epoch  178/500 Cost: 1.079434\n",
      "Epoch  179/500 Cost: 1.079376\n",
      "Epoch  180/500 Cost: 1.079317\n",
      "Epoch  181/500 Cost: 1.079276\n",
      "Epoch  182/500 Cost: 1.079213\n",
      "Epoch  183/500 Cost: 1.079150\n",
      "Epoch  184/500 Cost: 1.079100\n",
      "Epoch  185/500 Cost: 1.079034\n",
      "Epoch  186/500 Cost: 1.078986\n",
      "Epoch  187/500 Cost: 1.078930\n",
      "Epoch  188/500 Cost: 1.078876\n",
      "Epoch  189/500 Cost: 1.078811\n",
      "Epoch  190/500 Cost: 1.078760\n",
      "Epoch  191/500 Cost: 1.078709\n",
      "Epoch  192/500 Cost: 1.078654\n",
      "Epoch  193/500 Cost: 1.078588\n",
      "Epoch  194/500 Cost: 1.078542\n",
      "Epoch  195/500 Cost: 1.078490\n",
      "Epoch  196/500 Cost: 1.078413\n",
      "Epoch  197/500 Cost: 1.078378\n",
      "Epoch  198/500 Cost: 1.078313\n",
      "Epoch  199/500 Cost: 1.078263\n",
      "Epoch  200/500 Cost: 1.078205\n",
      "Epoch  201/500 Cost: 1.078150\n",
      "Epoch  202/500 Cost: 1.078089\n",
      "Epoch  203/500 Cost: 1.078036\n",
      "Epoch  204/500 Cost: 1.077981\n",
      "Epoch  205/500 Cost: 1.077933\n",
      "Epoch  206/500 Cost: 1.077873\n",
      "Epoch  207/500 Cost: 1.077814\n",
      "Epoch  208/500 Cost: 1.077761\n",
      "Epoch  209/500 Cost: 1.077700\n",
      "Epoch  210/500 Cost: 1.077642\n",
      "Epoch  211/500 Cost: 1.077591\n",
      "Epoch  212/500 Cost: 1.077536\n",
      "Epoch  213/500 Cost: 1.077487\n",
      "Epoch  214/500 Cost: 1.077420\n",
      "Epoch  215/500 Cost: 1.077368\n",
      "Epoch  216/500 Cost: 1.077313\n",
      "Epoch  217/500 Cost: 1.077253\n",
      "Epoch  218/500 Cost: 1.077204\n",
      "Epoch  219/500 Cost: 1.077138\n",
      "Epoch  220/500 Cost: 1.077089\n",
      "Epoch  221/500 Cost: 1.077034\n",
      "Epoch  222/500 Cost: 1.076971\n",
      "Epoch  223/500 Cost: 1.076915\n",
      "Epoch  224/500 Cost: 1.076870\n",
      "Epoch  225/500 Cost: 1.076808\n",
      "Epoch  226/500 Cost: 1.076765\n",
      "Epoch  227/500 Cost: 1.076710\n",
      "Epoch  228/500 Cost: 1.076648\n",
      "Epoch  229/500 Cost: 1.076575\n",
      "Epoch  230/500 Cost: 1.076522\n",
      "Epoch  231/500 Cost: 1.076484\n",
      "Epoch  232/500 Cost: 1.076419\n",
      "Epoch  233/500 Cost: 1.076360\n",
      "Epoch  234/500 Cost: 1.076321\n",
      "Epoch  235/500 Cost: 1.076252\n",
      "Epoch  236/500 Cost: 1.076187\n",
      "Epoch  237/500 Cost: 1.076154\n",
      "Epoch  238/500 Cost: 1.076095\n",
      "Epoch  239/500 Cost: 1.076030\n",
      "Epoch  240/500 Cost: 1.075976\n",
      "Epoch  241/500 Cost: 1.075921\n",
      "Epoch  242/500 Cost: 1.075865\n",
      "Epoch  243/500 Cost: 1.075817\n",
      "Epoch  244/500 Cost: 1.075765\n",
      "Epoch  245/500 Cost: 1.075703\n",
      "Epoch  246/500 Cost: 1.075643\n",
      "Epoch  247/500 Cost: 1.075589\n",
      "Epoch  248/500 Cost: 1.075537\n",
      "Epoch  249/500 Cost: 1.075476\n",
      "Epoch  250/500 Cost: 1.075428\n",
      "Epoch  251/500 Cost: 1.075371\n",
      "Epoch  252/500 Cost: 1.075315\n",
      "Epoch  253/500 Cost: 1.075265\n",
      "Epoch  254/500 Cost: 1.075196\n",
      "Epoch  255/500 Cost: 1.075149\n",
      "Epoch  256/500 Cost: 1.075089\n",
      "Epoch  257/500 Cost: 1.075040\n",
      "Epoch  258/500 Cost: 1.074985\n",
      "Epoch  259/500 Cost: 1.074934\n",
      "Epoch  260/500 Cost: 1.074877\n",
      "Epoch  261/500 Cost: 1.074808\n",
      "Epoch  262/500 Cost: 1.074760\n",
      "Epoch  263/500 Cost: 1.074711\n",
      "Epoch  264/500 Cost: 1.074646\n",
      "Epoch  265/500 Cost: 1.074580\n",
      "Epoch  266/500 Cost: 1.074549\n",
      "Epoch  267/500 Cost: 1.074479\n",
      "Epoch  268/500 Cost: 1.074422\n",
      "Epoch  269/500 Cost: 1.074381\n",
      "Epoch  270/500 Cost: 1.074317\n",
      "Epoch  271/500 Cost: 1.074259\n",
      "Epoch  272/500 Cost: 1.074212\n",
      "Epoch  273/500 Cost: 1.074147\n",
      "Epoch  274/500 Cost: 1.074099\n",
      "Epoch  275/500 Cost: 1.074047\n",
      "Epoch  276/500 Cost: 1.073988\n",
      "Epoch  277/500 Cost: 1.073940\n",
      "Epoch  278/500 Cost: 1.073876\n",
      "Epoch  279/500 Cost: 1.073825\n",
      "Epoch  280/500 Cost: 1.073765\n",
      "Epoch  281/500 Cost: 1.073700\n",
      "Epoch  282/500 Cost: 1.073666\n",
      "Epoch  283/500 Cost: 1.073594\n",
      "Epoch  284/500 Cost: 1.073541\n",
      "Epoch  285/500 Cost: 1.073489\n",
      "Epoch  286/500 Cost: 1.073438\n",
      "Epoch  287/500 Cost: 1.073380\n",
      "Epoch  288/500 Cost: 1.073324\n",
      "Epoch  289/500 Cost: 1.073265\n",
      "Epoch  290/500 Cost: 1.073217\n",
      "Epoch  291/500 Cost: 1.073160\n",
      "Epoch  292/500 Cost: 1.073096\n",
      "Epoch  293/500 Cost: 1.073050\n",
      "Epoch  294/500 Cost: 1.073002\n",
      "Epoch  295/500 Cost: 1.072937\n",
      "Epoch  296/500 Cost: 1.072888\n",
      "Epoch  297/500 Cost: 1.072824\n",
      "Epoch  298/500 Cost: 1.072782\n",
      "Epoch  299/500 Cost: 1.072720\n",
      "Epoch  300/500 Cost: 1.072669\n",
      "Epoch  301/500 Cost: 1.072610\n",
      "Epoch  302/500 Cost: 1.072560\n",
      "Epoch  303/500 Cost: 1.072496\n",
      "Epoch  304/500 Cost: 1.072440\n",
      "Epoch  305/500 Cost: 1.072393\n",
      "Epoch  306/500 Cost: 1.072339\n",
      "Epoch  307/500 Cost: 1.072283\n",
      "Epoch  308/500 Cost: 1.072237\n",
      "Epoch  309/500 Cost: 1.072175\n",
      "Epoch  310/500 Cost: 1.072119\n",
      "Epoch  311/500 Cost: 1.072055\n",
      "Epoch  312/500 Cost: 1.072006\n",
      "Epoch  313/500 Cost: 1.071946\n",
      "Epoch  314/500 Cost: 1.071895\n",
      "Epoch  315/500 Cost: 1.071841\n",
      "Epoch  316/500 Cost: 1.071775\n",
      "Epoch  317/500 Cost: 1.071733\n",
      "Epoch  318/500 Cost: 1.071678\n",
      "Epoch  319/500 Cost: 1.071627\n",
      "Epoch  320/500 Cost: 1.071562\n",
      "Epoch  321/500 Cost: 1.071519\n",
      "Epoch  322/500 Cost: 1.071465\n",
      "Epoch  323/500 Cost: 1.071408\n",
      "Epoch  324/500 Cost: 1.071353\n",
      "Epoch  325/500 Cost: 1.071302\n",
      "Epoch  326/500 Cost: 1.071234\n",
      "Epoch  327/500 Cost: 1.071186\n",
      "Epoch  328/500 Cost: 1.071131\n",
      "Epoch  329/500 Cost: 1.071073\n",
      "Epoch  330/500 Cost: 1.071017\n",
      "Epoch  331/500 Cost: 1.070968\n",
      "Epoch  332/500 Cost: 1.070904\n",
      "Epoch  333/500 Cost: 1.070855\n",
      "Epoch  334/500 Cost: 1.070798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  335/500 Cost: 1.070745\n",
      "Epoch  336/500 Cost: 1.070698\n",
      "Epoch  337/500 Cost: 1.070650\n",
      "Epoch  338/500 Cost: 1.070585\n",
      "Epoch  339/500 Cost: 1.070533\n",
      "Epoch  340/500 Cost: 1.070478\n",
      "Epoch  341/500 Cost: 1.070427\n",
      "Epoch  342/500 Cost: 1.070354\n",
      "Epoch  343/500 Cost: 1.070313\n",
      "Epoch  344/500 Cost: 1.070258\n",
      "Epoch  345/500 Cost: 1.070193\n",
      "Epoch  346/500 Cost: 1.070145\n",
      "Epoch  347/500 Cost: 1.070093\n",
      "Epoch  348/500 Cost: 1.070035\n",
      "Epoch  349/500 Cost: 1.069982\n",
      "Epoch  350/500 Cost: 1.069924\n",
      "Epoch  351/500 Cost: 1.069885\n",
      "Epoch  352/500 Cost: 1.069824\n",
      "Epoch  353/500 Cost: 1.069767\n",
      "Epoch  354/500 Cost: 1.069712\n",
      "Epoch  355/500 Cost: 1.069653\n",
      "Epoch  356/500 Cost: 1.069605\n",
      "Epoch  357/500 Cost: 1.069550\n",
      "Epoch  358/500 Cost: 1.069492\n",
      "Epoch  359/500 Cost: 1.069426\n",
      "Epoch  360/500 Cost: 1.069382\n",
      "Epoch  361/500 Cost: 1.069327\n",
      "Epoch  362/500 Cost: 1.069274\n",
      "Epoch  363/500 Cost: 1.069218\n",
      "Epoch  364/500 Cost: 1.069166\n",
      "Epoch  365/500 Cost: 1.069108\n",
      "Epoch  366/500 Cost: 1.069060\n",
      "Epoch  367/500 Cost: 1.068984\n",
      "Epoch  368/500 Cost: 1.068954\n",
      "Epoch  369/500 Cost: 1.068896\n",
      "Epoch  370/500 Cost: 1.068851\n",
      "Epoch  371/500 Cost: 1.068786\n",
      "Epoch  372/500 Cost: 1.068723\n",
      "Epoch  373/500 Cost: 1.068683\n",
      "Epoch  374/500 Cost: 1.068619\n",
      "Epoch  375/500 Cost: 1.068570\n",
      "Epoch  376/500 Cost: 1.068515\n",
      "Epoch  377/500 Cost: 1.068460\n",
      "Epoch  378/500 Cost: 1.068399\n",
      "Epoch  379/500 Cost: 1.068351\n",
      "Epoch  380/500 Cost: 1.068295\n",
      "Epoch  381/500 Cost: 1.068245\n",
      "Epoch  382/500 Cost: 1.068181\n",
      "Epoch  383/500 Cost: 1.068142\n",
      "Epoch  384/500 Cost: 1.068070\n",
      "Epoch  385/500 Cost: 1.068018\n",
      "Epoch  386/500 Cost: 1.067963\n",
      "Epoch  387/500 Cost: 1.067920\n",
      "Epoch  388/500 Cost: 1.067864\n",
      "Epoch  389/500 Cost: 1.067810\n",
      "Epoch  390/500 Cost: 1.067745\n",
      "Epoch  391/500 Cost: 1.067708\n",
      "Epoch  392/500 Cost: 1.067633\n",
      "Epoch  393/500 Cost: 1.067588\n",
      "Epoch  394/500 Cost: 1.067543\n",
      "Epoch  395/500 Cost: 1.067478\n",
      "Epoch  396/500 Cost: 1.067422\n",
      "Epoch  397/500 Cost: 1.067378\n",
      "Epoch  398/500 Cost: 1.067320\n",
      "Epoch  399/500 Cost: 1.067256\n",
      "Epoch  400/500 Cost: 1.067209\n",
      "Epoch  401/500 Cost: 1.067160\n",
      "Epoch  402/500 Cost: 1.067102\n",
      "Epoch  403/500 Cost: 1.067038\n",
      "Epoch  404/500 Cost: 1.067000\n",
      "Epoch  405/500 Cost: 1.066932\n",
      "Epoch  406/500 Cost: 1.066883\n",
      "Epoch  407/500 Cost: 1.066843\n",
      "Epoch  408/500 Cost: 1.066778\n",
      "Epoch  409/500 Cost: 1.066713\n",
      "Epoch  410/500 Cost: 1.066669\n",
      "Epoch  411/500 Cost: 1.066608\n",
      "Epoch  412/500 Cost: 1.066566\n",
      "Epoch  413/500 Cost: 1.066497\n",
      "Epoch  414/500 Cost: 1.066457\n",
      "Epoch  415/500 Cost: 1.066410\n",
      "Epoch  416/500 Cost: 1.066338\n",
      "Epoch  417/500 Cost: 1.066298\n",
      "Epoch  418/500 Cost: 1.066246\n",
      "Epoch  419/500 Cost: 1.066181\n",
      "Epoch  420/500 Cost: 1.066124\n",
      "Epoch  421/500 Cost: 1.066079\n",
      "Epoch  422/500 Cost: 1.066026\n",
      "Epoch  423/500 Cost: 1.065969\n",
      "Epoch  424/500 Cost: 1.065922\n",
      "Epoch  425/500 Cost: 1.065857\n",
      "Epoch  426/500 Cost: 1.065807\n",
      "Epoch  427/500 Cost: 1.065754\n",
      "Epoch  428/500 Cost: 1.065704\n",
      "Epoch  429/500 Cost: 1.065649\n",
      "Epoch  430/500 Cost: 1.065602\n",
      "Epoch  431/500 Cost: 1.065534\n",
      "Epoch  432/500 Cost: 1.065483\n",
      "Epoch  433/500 Cost: 1.065446\n",
      "Epoch  434/500 Cost: 1.065381\n",
      "Epoch  435/500 Cost: 1.065316\n",
      "Epoch  436/500 Cost: 1.065277\n",
      "Epoch  437/500 Cost: 1.065221\n",
      "Epoch  438/500 Cost: 1.065152\n",
      "Epoch  439/500 Cost: 1.065115\n",
      "Epoch  440/500 Cost: 1.065051\n",
      "Epoch  441/500 Cost: 1.064995\n",
      "Epoch  442/500 Cost: 1.064941\n",
      "Epoch  443/500 Cost: 1.064898\n",
      "Epoch  444/500 Cost: 1.064838\n",
      "Epoch  445/500 Cost: 1.064785\n",
      "Epoch  446/500 Cost: 1.064719\n",
      "Epoch  447/500 Cost: 1.064683\n",
      "Epoch  448/500 Cost: 1.064619\n",
      "Epoch  449/500 Cost: 1.064577\n",
      "Epoch  450/500 Cost: 1.064514\n",
      "Epoch  451/500 Cost: 1.064462\n",
      "Epoch  452/500 Cost: 1.064407\n",
      "Epoch  453/500 Cost: 1.064366\n",
      "Epoch  454/500 Cost: 1.064301\n",
      "Epoch  455/500 Cost: 1.064243\n",
      "Epoch  456/500 Cost: 1.064206\n",
      "Epoch  457/500 Cost: 1.064133\n",
      "Epoch  458/500 Cost: 1.064075\n",
      "Epoch  459/500 Cost: 1.064036\n",
      "Epoch  460/500 Cost: 1.063986\n",
      "Epoch  461/500 Cost: 1.063921\n",
      "Epoch  462/500 Cost: 1.063874\n",
      "Epoch  463/500 Cost: 1.063812\n",
      "Epoch  464/500 Cost: 1.063752\n",
      "Epoch  465/500 Cost: 1.063721\n",
      "Epoch  466/500 Cost: 1.063656\n",
      "Epoch  467/500 Cost: 1.063598\n",
      "Epoch  468/500 Cost: 1.063562\n",
      "Epoch  469/500 Cost: 1.063505\n",
      "Epoch  470/500 Cost: 1.063447\n",
      "Epoch  471/500 Cost: 1.063385\n",
      "Epoch  472/500 Cost: 1.063333\n",
      "Epoch  473/500 Cost: 1.063277\n",
      "Epoch  474/500 Cost: 1.063225\n",
      "Epoch  475/500 Cost: 1.063169\n",
      "Epoch  476/500 Cost: 1.063114\n",
      "Epoch  477/500 Cost: 1.063055\n",
      "Epoch  478/500 Cost: 1.063012\n",
      "Epoch  479/500 Cost: 1.062968\n",
      "Epoch  480/500 Cost: 1.062904\n",
      "Epoch  481/500 Cost: 1.062845\n",
      "Epoch  482/500 Cost: 1.062808\n",
      "Epoch  483/500 Cost: 1.062734\n",
      "Epoch  484/500 Cost: 1.062690\n",
      "Epoch  485/500 Cost: 1.062644\n",
      "Epoch  486/500 Cost: 1.062581\n",
      "Epoch  487/500 Cost: 1.062524\n",
      "Epoch  488/500 Cost: 1.062490\n",
      "Epoch  489/500 Cost: 1.062422\n",
      "Epoch  490/500 Cost: 1.062368\n",
      "Epoch  491/500 Cost: 1.062324\n",
      "Epoch  492/500 Cost: 1.062260\n",
      "Epoch  493/500 Cost: 1.062209\n",
      "Epoch  494/500 Cost: 1.062168\n",
      "Epoch  495/500 Cost: 1.062100\n",
      "Epoch  496/500 Cost: 1.062061\n",
      "Epoch  497/500 Cost: 1.062003\n",
      "Epoch  498/500 Cost: 1.061938\n",
      "Epoch  499/500 Cost: 1.061880\n",
      "Epoch  500/500 Cost: 1.061843\n"
     ]
    }
   ],
   "source": [
    "model = MRModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "nb_epochs = 500\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    # cost 계산\n",
    "    \n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 20번마다 로그 출력    \n",
    "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, cost.item()\n",
    "    ))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
