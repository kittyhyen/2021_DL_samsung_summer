{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day2_extra_MNIST_classification_with_BayesOptim.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OOEYKy1EGTF"
      },
      "source": [
        "### 라이브러리 설치\n",
        "[Adaptive Experimentation Platform](https://ax.dev/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMpk1c2Cg94W",
        "outputId": "6fda7a87-a9d6-4e68-9170-5a35ebfcf4ed"
      },
      "source": [
        "!pip install ax-platform"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ax-platform in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from ax-platform) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ax-platform) (1.4.1)\n",
            "Requirement already satisfied: botorch==0.5.0 in /usr/local/lib/python3.7/dist-packages (from ax-platform) (0.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from ax-platform) (2.11.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ax-platform) (1.1.5)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.7/dist-packages (from ax-platform) (2.7.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from ax-platform) (4.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->ax-platform) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->ax-platform) (1.0.1)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from botorch==0.5.0->ax-platform) (1.9.0+cu102)\n",
            "Requirement already satisfied: gpytorch>=1.5 in /usr/local/lib/python3.7/dist-packages (from botorch==0.5.0->ax-platform) (1.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->ax-platform) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->ax-platform) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ax-platform) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly->ax-platform) (1.15.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->ax-platform) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.1->botorch==0.5.0->ax-platform) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMKjYPPlX9PQ"
      },
      "source": [
        "### Reproducibility\n",
        "[PyTorch](https://pytorch.org/docs/stable/notes/randomness.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcTDgNn3WofN"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWEe_m9YYNFi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af6bd28-2e20-43a5-b681-953d6ab80088"
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "# try:\n",
        "#     torch.use_deterministic_algorithms(True)\n",
        "# except AttributeError:\n",
        "#     torch.set_deterministic(True)\n",
        "# torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ff0a5952df0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6cSFF7faEsX"
      },
      "source": [
        "### MNIST 데이터\n",
        "[MNIST](http://yann.lecun.com/exdb/mnist/)  \n",
        "[PyTorch](https://pytorch.org/vision/stable/datasets.html#torchvision.datasets.MNIST)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_iFiDs_ZpL6"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tJ08QdHZvNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc412e61-d80f-409c-c243-1f8b5c5fd5af"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5), (0.5))\n",
        "])\n",
        "\n",
        "trainset = MNIST('./data', train=True, download=True, transform=transform)\n",
        "testset = MNIST('./data', train=False, transform=transform)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khK77Jm8c9tz"
      },
      "source": [
        "### PyTorch 분류기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXLLmYpuq72l"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6py3lmQWdCdT"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWfZfePwcYHj"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(28 * 28, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        out = self.fc(x)\n",
        "        return out"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcHVFlktECUs"
      },
      "source": [
        "### Bayesian Optimization with Ax-Platform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vDRPZAmAPbs"
      },
      "source": [
        "def train(model, loader, params, device):\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=params.get(\"lr\", 0.001))\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for _ in range(5):\n",
        "        for xs, ys in loader:\n",
        "            xs, ys = xs.to(device), ys.to(device)\n",
        "            output = model(xs)\n",
        "            loss = criterion(output, ys)\n",
        "            optim.zero_grad()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kao2vGDkCBHs"
      },
      "source": [
        "def evaluate(model, loader, params, device):\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    model.to(device)\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xs, ys in loader:\n",
        "            xs, ys = xs.to(device), ys.to(device)\n",
        "            output = model(xs)\n",
        "\n",
        "            _, predicted = torch.max(output, 1)\n",
        "\n",
        "            total += ys.size(0)\n",
        "            correct += (predicted == ys).sum().item()\n",
        "\n",
        "    return correct / total"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29eozuR6GctR"
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkWB-JSqBFJP"
      },
      "source": [
        "def eval_fn(params):\n",
        "    trainloader = DataLoader(trainset, batch_size=params.get(\"batchsize\", 1024), shuffle=True)\n",
        "    testloader = DataLoader(testset, batch_size=params.get(\"batchsize\", 1024))\n",
        "    model = Net()\n",
        "    trained_model = train(model, trainloader, params, device)\n",
        "    acc = evaluate(trained_model, testloader, params, device)\n",
        "    return acc"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWKxt3Kb_H_U"
      },
      "source": [
        "from ax.service.managed_loop import optimize"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4hfb67E_DXA",
        "outputId": "a6864c55-5270-4f8c-dbef-f39a05db4643"
      },
      "source": [
        "best_params, _, _, model = optimize(\n",
        "    parameters=[\n",
        "        {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [0.001, 0.1], \"log_scale\": True},\n",
        "        {\"name\": \"batchsize\", \"type\": \"range\", \"bounds\": [512, 600]},\n",
        "        {\"name\": \"epochs\", \"type\": \"range\", \"bounds\": [10, 30]}\n",
        "    ]    # 하이퍼파라미터와 범위\n",
        "    evaluation_function=eval_fn,    # 학습과 테스트 함수\n",
        "    objective_name='accuracy',    # 목표 (eval_fn이 반환하는 값)\n",
        "    total_trials=20,    # 트라이얼 수\n",
        "    random_seed=SEED\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO 07-11 19:45:08] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter lr. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
            "[INFO 07-11 19:45:08] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter batchsize. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
            "[INFO 07-11 19:45:08] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter epochs. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
            "[INFO 07-11 19:45:08] ax.modelbridge.dispatch_utils: Using GPEI (Bayesian optimization) since there are more continuous parameters than there are categories for the unordered categorical parameters.\n",
            "[INFO 07-11 19:45:08] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 5 trials, GPEI for subsequent trials]). Iterations after 5 will take longer to generate due to  model-fitting.\n",
            "[INFO 07-11 19:45:08] ax.service.managed_loop: Started full optimization with 20 steps.\n",
            "[INFO 07-11 19:45:08] ax.service.managed_loop: Running optimization trial 1...\n",
            "[INFO 07-11 19:48:30] ax.service.managed_loop: Running optimization trial 2...\n",
            "[INFO 07-11 19:50:01] ax.service.managed_loop: Running optimization trial 3...\n",
            "[INFO 07-11 19:51:56] ax.service.managed_loop: Running optimization trial 4...\n",
            "[INFO 07-11 19:54:18] ax.service.managed_loop: Running optimization trial 5...\n",
            "[INFO 07-11 19:55:59] ax.service.managed_loop: Running optimization trial 6...\n",
            "[INFO 07-11 19:58:15] ax.service.managed_loop: Running optimization trial 7...\n",
            "[INFO 07-11 20:00:36] ax.service.managed_loop: Running optimization trial 8...\n",
            "[INFO 07-11 20:03:01] ax.service.managed_loop: Running optimization trial 9...\n",
            "[INFO 07-11 20:05:03] ax.service.managed_loop: Running optimization trial 10...\n",
            "[INFO 07-11 20:07:11] ax.service.managed_loop: Running optimization trial 11...\n",
            "[INFO 07-11 20:08:38] ax.service.managed_loop: Running optimization trial 12...\n",
            "[INFO 07-11 20:10:33] ax.service.managed_loop: Running optimization trial 13...\n",
            "[INFO 07-11 20:12:08] ax.service.managed_loop: Running optimization trial 14...\n",
            "[INFO 07-11 20:14:37] ax.service.managed_loop: Running optimization trial 15...\n",
            "[INFO 07-11 20:17:36] ax.service.managed_loop: Running optimization trial 16...\n",
            "[INFO 07-11 20:20:42] ax.service.managed_loop: Running optimization trial 17...\n",
            "[INFO 07-11 20:24:01] ax.service.managed_loop: Running optimization trial 18...\n",
            "[INFO 07-11 20:26:55] ax.service.managed_loop: Running optimization trial 19...\n",
            "[INFO 07-11 20:28:03] ax.service.managed_loop: Running optimization trial 20...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX2Sp4gYFA_O"
      },
      "source": [
        "#### Optimized Hyperparameters 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wcy3AbQZrYzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b2c3255-4485-4f49-e76b-1c757fe274b4"
      },
      "source": [
        "print(best_params)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'lr': 0.004281206840537801, 'batchsize': 587, 'epochs': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}